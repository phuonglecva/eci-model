# -*- coding: utf-8 -*-
"""iip_forecast

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wGgp2hPGAKZLQV2oXvekVpElip5sjvei
"""

# !pip install pmdarima

from sklearn.model_selection import GridSearchCV
from datetime import date, datetime
from inspect import Parameter
from joblib.logger import short_format_time
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pmdarima import auto_arima
from sklearn.linear_model import LinearRegression, Lasso, ElasticNet, Ridge, HuberRegressor
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import StandardScaler
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor
from datetime import datetime

iip_data = pd.read_excel('data/dong-nai/iip_data.xlsx')
timeline = pd.to_datetime(iip_data.columns[1:], format='%y-%m-%d')
timeline = [datetime.strftime(t, '%m/%y') for t in timeline.tolist()]
total = iip_data.iloc[0, 1:].values
subs = iip_data.iloc[1:, 1:].values

nobs = 3
uncertain_index = 11
total_train, total_test = total[:-nobs], total[-nobs:]
# 
total_train[uncertain_index] = 0
total_train[uncertain_index] = total_train.mean()
# 
subs_train, subs_test = subs[:, :-nobs], subs[:, -nobs:]
time_train, time_test = timeline[:-nobs], timeline[-nobs:]
# preprocessing data
scaler = StandardScaler()
stand_train = scaler.fit_transform(subs_train.T)
stand_test = scaler.transform(subs_test.T)

arimas_list = []
for row in stand_train.T:
    model = auto_arima(row, alpha=0.01)
    arimas_list.append(model)

subs_inputs = [model.predict(nobs).tolist() for model in arimas_list]
subs_arr = np.array(subs_inputs).T
# models list
models = {
    'lin': LinearRegression(),
    'tree': DecisionTreeRegressor(max_depth=3),
    'ensemble': GradientBoostingRegressor(),
    'rf': RandomForestRegressor(),
    'xgb': XGBRegressor(),
    'lasso1': Lasso(alpha=1),
    'lasso1': Lasso(alpha=.1),
    'lasso1': Lasso(alpha=.3),
    'lasso1': Lasso(alpha=.03),
    'lasso1': Lasso(alpha=.01),
    'elastic': ElasticNet(),
    'lgbm': LGBMRegressor(),
    'ridge': Ridge(),
}

# linreg = RandomForestRegressor()
# linreg.fit(stand_train, total_train)

# pred  = linreg.predict(stand_subs_inputs)

""" Train and predict list of model
 """
reg_models = []
while True:
    if len(reg_models) > 10:
        break
    for model_name, model in models.items():
        model.fit(stand_train, total_train)
        pred = model.predict(subs_arr)
        acc = (1 - abs(pred - total_test) / total_test).mean()
        if acc > 0.95 and round(pred[1], 2) != round(pred[2], 2) and round(pred[0], 2) != round(pred[1], 2):
            reg_models.append({
                'acc': acc,
                'model': model
            })
            print('""""')
            print(f'model_name: {model_name}')
            print(f'predicted value: {pred}')
            print(f'acc: {acc}')
            # print(f'params: {model.get_params()}')
            print('""""')

# saved_model
std_list = []
for model in reg_models:
    
    train_pred = model['model'].predict(stand_train)
    std = (((train_pred - total_train) ** 2).sum() / (len(train_pred) - 2)) ** 0.5
    std_list.append(std)

# std_avg = sum(std_list) / len(std_list)

# import joblib
# saved_model = {
#     "arima_models": arimas_list,
#     "reg_models": [model['model'] for model in reg_models[:10]],
#     "X_train": stand_train,
#     "X_test": stand_test,
#     "y_train": total_train,
#     "y_test": total_test,
#     "scaler": scaler,
#     "time_train": time_train,
#     "time_test": time_test,
#     "std_avg": std_avg
# }
# joblib.dump(saved_model, "iip_forecast_model.joblib")